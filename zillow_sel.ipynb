{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import csv\n",
    "import math\n",
    "import random\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import InvalidSessionIdException\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pymouse import PyMouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 爬房價網址\n",
    "def get_house_links(url, driver, next_page_xpath):\n",
    "    house_links=[]\n",
    "    driver.get(url)\n",
    "    driver.set_window_size(800, 1000)\n",
    "    time.sleep(3)\n",
    "    pages = driver.find_element_by_xpath('//*[@id=\"grid-search-results\"]/div[1]/div/span[1]')\n",
    "    \n",
    "    if int(pages.text.replace(' results','')) < 40 :\n",
    "        get_html_text(house_links, next_page_xpath)\n",
    "           \n",
    "    elif int(pages.text.replace(' results','')) % 40 == 0:\n",
    "        pages = math.floor(int(pages.text.replace(' results',''))/40)\n",
    "        for i in range(pages):\n",
    "            get_html_text(house_links, next_page_xpath)\n",
    "             \n",
    "    else :\n",
    "        pages = math.floor(int(pages.text.replace(' results',''))/40)\n",
    "        for i in range(pages+1):\n",
    "            get_html_text(house_links, next_page_xpath)\n",
    "    \n",
    "    return house_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 爬房價網址\n",
    "def get_html_text(house_links, next_page_xpath):\n",
    "    for j in range(7):\n",
    "        ActionChains(driver).send_keys(Keys.PAGE_DOWN).perform()  \n",
    "        time.sleep(2)\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    listings = soup.find_all(\"a\", class_=\"list-card-link list-card-link-top-margin\")\n",
    "    page_links = [row['href'] for row in listings]\n",
    "    next_page = driver.find_element_by_xpath(next_page_xpath) \n",
    "    driver.execute_script(\"arguments[0].click();\", next_page)\n",
    "    time.sleep(np.random.lognormal(0,1)*2)\n",
    "    house_links += page_links\n",
    "    \n",
    "    return house_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_house_data(driver,house_links_flat):\n",
    "    try:\n",
    "        # 自動登入\n",
    "        # auto_login(driver,house_links_flat[0])\n",
    "        \n",
    "        error_list = []\n",
    "        house_data = []\n",
    "        for link in house_links_flat:\n",
    "            time.sleep(np.random.lognormal(0,1)*1)\n",
    "\n",
    "            soup = get_html_data(link,driver)\n",
    "\n",
    "            time.sleep(6)\n",
    "\n",
    "            houseprice = get_price(soup)\n",
    "\n",
    "            if type(houseprice) == float:\n",
    "                error_list += [link]\n",
    "\n",
    "            sale_date =get_sale_date(soup)\n",
    "            address = get_address(soup)\n",
    "\n",
    "            time.sleep(1)\n",
    "            time.sleep(np.random.lognormal(0,1))\n",
    "\n",
    "            bd = get_bd(soup)\n",
    "            ba = get_ba(soup)\n",
    "            floor_size = get_floor_size(soup)\n",
    "            housetype = get_type(soup)\n",
    "            year_built = get_year_built(soup)\n",
    "\n",
    "            lot_size = get_lot_size(soup)\n",
    "            hoa = get_hoa(soup)\n",
    "            walk_score = get_walk_score(soup)\n",
    "            transit_score = get_transit_score(soup)\n",
    "\n",
    "            time.sleep(np.random.lognormal(0,1))\n",
    "\n",
    "            pt = get_pt(soup)\n",
    "            ta = get_ta(soup)\n",
    "            school1 = get_school1(soup)\n",
    "            school2 = get_school2(soup)\n",
    "            school3 = get_school3(soup)\n",
    "            mls = get_mls(soup)\n",
    "\n",
    "            time.sleep(np.random.lognormal(0,1))\n",
    "\n",
    "            house_data.append([mls, bd, ba, floor_size, address, sale_date, walk_score, transit_score, school1, school2, school3, housetype, year_built, lot_size, pt, ta, hoa, houseprice])        \n",
    "\n",
    "        if error_list != []:\n",
    "            save_error_html(error_list)\n",
    "            \n",
    "        return house_data\n",
    "    except:\n",
    "        print('error')\n",
    "        if error_list != []:\n",
    "            save_error_html(error_list)\n",
    "        return house_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html_data(url, driver):\n",
    "    driver.get(url)\n",
    "    htmlsleep()\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 抓不到價錢時, 判定發生機器人或者頁面找不到(404), 程式暫停後續抓OR回空值\n",
    "def get_price(soup):\n",
    "    try:\n",
    "        try:\n",
    "            houseprice = driver.find_element_by_xpath('//*[@id=\"home-details-content\"]/div/div/div[1]/div[2]/div[2]/div[2]/div[1]/p/span[1]/span[2]')\n",
    "            houseprice = int(houseprice.text.replace(': $','').replace(',',''))\n",
    "            return houseprice\n",
    "        except NoSuchElementException:\n",
    "            try:\n",
    "                mouseCount = 0\n",
    "                while driver.find_element_by_xpath('/html/body/main') != None:\n",
    "                    if mouseCount == 10:\n",
    "                        print('robot error')\n",
    "                        htmlsleep()\n",
    "                        break\n",
    "                    time.sleep(random.randint(2,4))\n",
    "                    check_root()\n",
    "                    mouseCount +=1\n",
    "            except NoSuchElementException:            \n",
    "                houseprice = driver.find_element_by_xpath('//*[@id=\"home-details-content\"]/div/div/div[1]/div[2]/div[2]/div[2]/div[1]/p/span[1]/span[2]')\n",
    "                houseprice = int(houseprice.text.replace(': $','').replace(',',''))\n",
    "                return houseprice\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_root():\n",
    "    m = PyMouse()\n",
    "    x= random.randint(500,700)\n",
    "    y = random.randint(400,450)\n",
    "    mx = random.randint(0,10)\n",
    "    my = random.randint(0,10)\n",
    "    m.press(x,y)\n",
    "    time.sleep(random.randint(3,5))\n",
    "    m.release(x+mx, y+my)\n",
    "    print('check_robot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 發生機器人時睡一下及開網頁時\n",
    "def htmlsleep():\n",
    "    time.sleep(np.random.lognormal(0,1))\n",
    "    random_time = [4,5,6,7]\n",
    "    time.sleep(random.choice(random_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sale_date(soup):\n",
    "    try:\n",
    "        sale_date = driver.find_element_by_xpath('//*[@id=\"home-details-content\"]/div/div/div[1]/div[2]/div[2]/div[2]/div[1]/p/span[2]')\n",
    "        sale_date = sale_date.text.replace('Sold on ','')\n",
    "        return sale_date\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_address(soup):\n",
    "    try:\n",
    "        address = driver.find_element_by_xpath('//*[@id=\"ds-chip-property-address\"]')        \n",
    "        return address.text\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bd(soup):\n",
    "    try:\n",
    "        housebedroom = driver.find_element_by_xpath('//*[@id=\"home-details-content\"]/div/div/div[1]/div[2]/div[2]/div[2]/div[1]/div[1]/span/span[1]/span[1]')\n",
    "        housebedroom = int(housebedroom.text)\n",
    "        return housebedroom\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ba(soup):\n",
    "    try:\n",
    "        try:\n",
    "            housebathroom = driver.find_element_by_xpath('//*[@id=\"home-details-content\"]/div/div/div[1]/div[2]/div[2]/div[2]/div[1]/div[1]/span/button/span/span[1]')\n",
    "            return float(housebathroom.text)\n",
    "        except NoSuchElementException:\n",
    "            housebathroom = driver.find_element_by_xpath('//*[@id=\"home-details-content\"]/div/div/div[1]/div[2]/div[2]/div[2]/div[1]/div[1]/span/span[3]/span[1]')\n",
    "            housebathroom = float(housebathroom.text)\n",
    "            return housebathroom\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_floor_size(soup):\n",
    "    try:\n",
    "        try:\n",
    "            floor_size = driver.find_element_by_xpath('//*[@id=\"home-details-content\"]/div/div/div[1]/div[2]/div[2]/div[2]/div[1]/div[1]/span/span[4]/span[1]')\n",
    "            floor_size = int(floor_size.text.replace('sqft','').replace(',',''))\n",
    "            return floor_size\n",
    "        except NoSuchElementException:\n",
    "            floor_size = driver.find_element_by_xpath('//*[@id=\"home-details-content\"]/div/div/div[1]/div[2]/div[2]/div[2]/div[1]/div[1]/span/span[5]/span[1]')\n",
    "            floor_size = int(floor_size.text.replace('sqft','').replace(',',''))\n",
    "            return floor_size\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_type(soup):\n",
    "    try:\n",
    "        try:\n",
    "            housetype = driver.find_element_by_xpath('//*[@id=\"home-details-content\"]/div/div/div[1]/div[2]/div[2]/div[3]/div/div/div/ul/li/div[6]/div/div[1]/ul/li[1]/span[2]')\n",
    "            return housetype.text\n",
    "        except NoSuchElementException:\n",
    "            housetype = driver.find_element_by_xpath('//*[@id=\"home-details-content\"]/div/div/div[1]/div[2]/div[2]/div[3]/div/div/div/ul/li/div[7]/div/div[1]/ul/li[1]/span[2]')\n",
    "            return housetype.text\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_year_built(soup):\n",
    "    try:\n",
    "        try:\n",
    "            year_built = driver.find_element_by_xpath('//*[@id=\"home-details-content\"]/div/div/div[1]/div[2]/div[2]/div[3]/div/div/div/ul/li/div[6]/div/div[1]/ul/li[2]/span[2]')\n",
    "            return year_built.text\n",
    "        except NoSuchElementException:\n",
    "            year_built = driver.find_element_by_xpath('//*[@id=\"home-details-content\"]/div/div/div[1]/div[2]/div[2]/div[3]/div/div/div/ul/li/div[7]/div/div[1]/ul/li[2]/span[2]')\n",
    "            return year_built.text\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_lot_size(soup):\n",
    "    try:         \n",
    "        try:\n",
    "            try:\n",
    "                try:\n",
    "                    lot = driver.find_element_by_xpath('//*[@id=\"home-details-content\"]/div/div/div[1]/div[2]/div[2]/div[3]/div/div/div/ul/li/div[7]/div/div[1]/ul/li[6]/span[2]')\n",
    "                    if lot.text[-1] == 's' or lot.text[-1] == 't':\n",
    "                        return lot.text\n",
    "                    else:\n",
    "                        raise NoSuchElementException\n",
    "                except NoSuchElementException:\n",
    "                    lot = driver.find_element_by_xpath('//*[@id=\"home-details-content\"]/div/div/div[1]/div[2]/div[2]/div[3]/div/div/div/ul/li/div[7]/div/div[1]/ul/li[7]/span[2]')\n",
    "                    if lot.text[-1] == 's' or lot.text[-1] == 't':\n",
    "                        return lot.text\n",
    "                    else:\n",
    "                        raise NoSuchElementException\n",
    "            except NoSuchElementException:\n",
    "                lot = driver.find_element_by_xpath('//*[@id=\"home-details-content\"]/div/div/div[1]/div[2]/div[2]/div[3]/div/div/div/ul/li/div[6]/div/div[1]/ul/li[7]/span[2]')\n",
    "                if lot.text[-1] == 's' or lot.text[-1] == 't':\n",
    "                    return lot.text\n",
    "                else:\n",
    "                    raise NoSuchElementException\n",
    "        except NoSuchElementException:\n",
    "            lot = driver.find_element_by_xpath('//*[@id=\"home-details-content\"]/div/div/div[1]/div[2]/div[2]/div[3]/div/div/div/ul/li/div[6]/div/div[1]/ul/li[6]/span[2]')\n",
    "            if lot.text[-1] == 's' or lot.text[-1] == 't':\n",
    "                return lot.text\n",
    "            else:\n",
    "                raise NoSuchElementException\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_hoa(soup):\n",
    "    try:\n",
    "        try:\n",
    "            try:\n",
    "                hoa = driver.find_element_by_xpath('//*[@id=\"home-details-content\"]/div/div/div[1]/div[2]/div[2]/div[3]/div/div/div/ul/li/div[7]/div/div[1]/ul/li[6]/span[2]')\n",
    "                if hoa.text[0] == '$':\n",
    "                    return hoa.text.replace('$','').replace(' monthly','')\n",
    "                else:\n",
    "                    raise NoSuchElementException\n",
    "            except NoSuchElementException:\n",
    "                hoa = driver.find_element_by_xpath('//*[@id=\"home-details-content\"]/div/div/div[1]/div[2]/div[2]/div[3]/div/div/div/ul/li/div[6]/div/div[1]/ul/li[6]/span[2]')            \n",
    "                if hoa.text[0] == '$':\n",
    "                    return hoa.text.replace('$','').replace(' monthly','')\n",
    "                else:\n",
    "                    raise NoSuchElementException\n",
    "        except NoSuchElementException:\n",
    "            hoa = driver.find_element_by_xpath('//*[@id=\"home-details-content\"]/div/div/div[1]/div[2]/div[2]/div[3]/div/div/div/ul/li/div[7]/div/div[1]/ul/li[6]/span[2]')        \n",
    "            if hoa.text[0] == '$':\n",
    "                return hoa.text.replace('$','').replace(' monthly','')\n",
    "            else:\n",
    "                raise NoSuchElementException\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_walk_score(soup):\n",
    "    try:\n",
    "        walk_score_t = driver.find_element_by_xpath('//*[@id=\"walk-score-text\"]')\n",
    "        try:\n",
    "            walk_score = driver.find_element_by_xpath('//*[@id=\"home-details-content\"]/div/div/div[1]/div[2]/div[2]/div[3]/div/div/div/ul/li/div[8]/div[1]/div[1]/ul/li[1]/a/span')\n",
    "            return int(walk_score.text)\n",
    "        except NoSuchElementException:\n",
    "            walk_score = driver.find_element_by_xpath('//*[@id=\"home-details-content\"]/div/div/div[1]/div[2]/div[2]/div[3]/div/div/div/ul/li/div[9]/div[1]/div[1]/ul/li[1]/a/span')\n",
    "            return int(walk_score.text)\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transit_score(soup):\n",
    "    try:\n",
    "        transit_score_t = driver.find_element_by_xpath('//*[@id=\"transit-score-text\"]')\n",
    "        try:\n",
    "            try:\n",
    "                try:            \n",
    "                    transit_score = driver.find_element_by_xpath('//*[@id=\"home-details-content\"]/div/div/div[1]/div[2]/div[2]/div[3]/div/div/div/ul/li/div[9]/div[1]/div[1]/ul/li[2]/a/span')\n",
    "                    return int(transit_score.text)\n",
    "                except NoSuchElementException:\n",
    "                    transit_score = driver.find_element_by_xpath('//*[@id=\"home-details-content\"]/div/div/div[1]/div[2]/div[2]/div[3]/div/div/div/ul/li/div[8]/div[1]/div[1]/ul/li[2]/a/span')\n",
    "                    return int(transit_score.text) \n",
    "            except NoSuchElementException:\n",
    "                transit_score = driver.find_element_by_xpath('//*[@id=\"home-details-content\"]/div/div/div[1]/div[2]/div[2]/div[3]/div/div/div/ul/li/div[9]/div[1]/div[1]/ul/li[1]/a/span')\n",
    "                return int(transit_score.text)                \n",
    "        except NoSuchElementException:\n",
    "            transit_score = driver.find_element_by_xpath('//*[@id=\"home-details-content\"]/div/div/div[1]/div[2]/div[2]/div[3]/div/div/div/ul/li/div[8]/div[1]/div[1]/ul/li[1]/a/span')\n",
    "            return int(transit_score.text)\n",
    "    except:\n",
    "        return np.nan    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pt(soup):\n",
    "    try:\n",
    "        try: \n",
    "            pt = driver.find_element_by_xpath('//*[@id=\"home-details-content\"]/div/div/div[1]/div[2]/div[2]/div[3]/div/div/div/ul/li/div[7]/div[1]/div[2]/div/table/tbody/tr[1]/td[2]/span[1]')\n",
    "            pt = int(pt.text.replace('$','').replace(',',''))\n",
    "            return pt\n",
    "        except NoSuchElementException:          \n",
    "            pt = driver.find_element_by_xpath('//*[@id=\"home-details-content\"]/div/div/div[1]/div[2]/div[2]/div[3]/div/div/div/ul/li/div[8]/div[1]/div[2]/div/table/tbody/tr[1]/td[2]/span[1]')\n",
    "            pt = int(pt.text.replace('$','').replace(',',''))\n",
    "            return pt\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ta(soup):\n",
    "    try:\n",
    "        try:\n",
    "            ta = driver.find_element_by_xpath('//*[@id=\"home-details-content\"]/div/div/div[1]/div[2]/div[2]/div[3]/div/div/div/ul/li/div[7]/div[1]/div[2]/div/table/tbody/tr[1]/td[3]/span[1]')\n",
    "            ta = int(ta.text.replace('$','').replace(',',''))\n",
    "            return ta\n",
    "        except NoSuchElementException:\n",
    "            ta = driver.find_element_by_xpath('//*[@id=\"home-details-content\"]/div/div/div[1]/div[2]/div[2]/div[3]/div/div/div/ul/li/div[8]/div[1]/div[2]/div/table/tbody/tr[1]/td[3]/span[1]')\n",
    "            ta = int(ta.text.replace('$','').replace(',',''))\n",
    "            return ta\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_school1(soup):\n",
    "    try:\n",
    "        school1 = driver.find_element_by_xpath('//*[@id=\"ds-nearby-schools-list\"]/li[1]/div[1]/div/span[1]')        \n",
    "        return school1.text\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_school2(soup):\n",
    "    try:\n",
    "        school2 = driver.find_element_by_xpath('//*[@id=\"ds-nearby-schools-list\"]/li[2]/div[1]/div/span[1]')        \n",
    "        return school2.text\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_school3(soup):\n",
    "    try:\n",
    "        school3 = driver.find_element_by_xpath('//*[@id=\"ds-nearby-schools-list\"]/li[3]/div[1]/div/span[1]')        \n",
    "        return school3.text\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mls(soup):\n",
    "    try:\n",
    "        try:\n",
    "            mls = driver.find_element_by_xpath('//*[@id=\"home-details-content\"]/div/div/div[1]/div[2]/div[2]/div[3]/div/div/div/ul/li/div[5]/div[1]/div[3]/div[2]')\n",
    "            mls = mls.text.replace('MLS#:','')\n",
    "            return mls\n",
    "        except NoSuchElementException:         \n",
    "            mls = driver.find_element_by_xpath('//*[@id=\"home-details-content\"]/div/div/div[1]/div[2]/div[2]/div[3]/div/div/div/ul/li/div[6]/div[1]/div[3]/div[2]')\n",
    "            mls = mls.text.replace('MLS#:','')\n",
    "            return mls\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_html(house_links_pages):\n",
    "    file_name = \"house_html%s_%s.csv\" % (str(time.strftime(\"%Y-%m-%d\")), str(time.strftime(\"%H%M%S\")))\n",
    "    columns = ['html']\n",
    "    pd.DataFrame(house_links_pages, columns = columns).to_csv(file_name, index = False, encoding = \"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_error_html(error_list):\n",
    "    file_name = \"error_html%s_%s.csv\" % (str(time.strftime(\"%Y-%m-%d\")), str(time.strftime(\"%H%M%S\")))\n",
    "    columns = ['html']\n",
    "    pd.DataFrame(error_list, columns = columns).to_csv(file_name, index = False, encoding = \"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自動登錄功能\n",
    "def auto_login(driver, url):\n",
    "\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "\n",
    "    sign_in1 = driver.find_element_by_xpath('//*[@id=\"page-header-container\"]/header/nav/div[1]/ul/li[1]/a/span') \n",
    "    driver.execute_script(\"arguments[0].click();\", sign_in1)\n",
    "    time.sleep(2)\n",
    "\n",
    "    email = driver.find_element_by_xpath('//*[@id=\"reg-login-email\"]')\n",
    "    email.send_keys('帳號')\n",
    "    time.sleep(2)\n",
    "\n",
    "    password = driver.find_element_by_xpath('//*[@id=\"inputs-password\"]')\n",
    "    password.send_keys('密碼')\n",
    "    time.sleep(2)\n",
    "\n",
    "    button = driver.find_element_by_xpath('//*[@id=\"login-tab_panel\"]/form/div[3]/div/input')\n",
    "    button.click()\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 讀取下載房價網址.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取csv檔\n",
    "file = './98119.csv'\n",
    "with open(file) as csvFile:\n",
    "    csvReader = csv.reader(csvFile)\n",
    "    datas = list(csvReader)\n",
    "house_links_pages = []    \n",
    "for data in datas[1:]:\n",
    "    house_links_pages += data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 爬取房價資訊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 執行程式, 可與下行合併\n",
    "driver = webdriver.Chrome(\"./chromedriver\")\n",
    "# house_links_pages[?:?] 調整頁數\n",
    "house_links_flat = get_house_data(driver, house_links_pages[157:])\n",
    "driver.close()\n",
    "print('Finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 執行完, 儲存房屋資料\n",
    "file_name = \"%s_%s.csv\" % (str(time.strftime(\"%Y-%m-%d\")), str(time.strftime(\"%H%M%S\")))\n",
    "columns = ['mls','housebedroom','housebathroom','sqft','address','soldout','walkscore','transitscore','school1','school2','school3','housetype','houseyear','lot','pt','ta','hoa','houseprice']\n",
    "pd.DataFrame(house_links_flat, columns = columns).to_csv(file_name, index = False, encoding = \"UTF-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 取得房價網址"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"./chromedriver\")\n",
    "# 因頁數不一樣需要改下一頁的xpath\n",
    "next_page_xpath = '//*[@id=\"grid-search-results\"]/div[2]/nav/ul/li[10]/a'\n",
    "# 改網頁\n",
    "htmls = 'https://www.zillow.com/federal-way-wa-98003/sold/house_type/1-_beds/?searchQueryState=%7B%22pagination%22%3A%7B%7D%2C%22usersSearchTerm%22%3A%2298003%22%2C%22mapBounds%22%3A%7B%22west%22%3A-122.42200673095704%2C%22east%22%3A-122.20983326904297%2C%22south%22%3A47.26186910664669%2C%22north%22%3A47.35568303676819%7D%2C%22regionSelection%22%3A%5B%7B%22regionId%22%3A99491%2C%22regionType%22%3A7%7D%5D%2C%22isMapVisible%22%3Atrue%2C%22filterState%22%3A%7B%22ah%22%3A%7B%22value%22%3Atrue%7D%2C%22rs%22%3A%7B%22value%22%3Atrue%7D%2C%22fsba%22%3A%7B%22value%22%3Afalse%7D%2C%22fsbo%22%3A%7B%22value%22%3Afalse%7D%2C%22nc%22%3A%7B%22value%22%3Afalse%7D%2C%22cmsn%22%3A%7B%22value%22%3Afalse%7D%2C%22auc%22%3A%7B%22value%22%3Afalse%7D%2C%22fore%22%3A%7B%22value%22%3Afalse%7D%2C%22beds%22%3A%7B%22min%22%3A1%7D%2C%22tow%22%3A%7B%22value%22%3Afalse%7D%2C%22mf%22%3A%7B%22value%22%3Afalse%7D%2C%22con%22%3A%7B%22value%22%3Afalse%7D%2C%22land%22%3A%7B%22value%22%3Afalse%7D%2C%22apa%22%3A%7B%22value%22%3Afalse%7D%2C%22manu%22%3A%7B%22value%22%3Afalse%7D%2C%22price%22%3A%7B%22min%22%3A550000%7D%2C%22mp%22%3A%7B%22min%22%3A1772%7D%7D%2C%22isListVisible%22%3Atrue%2C%22mapZoom%22%3A12%7D'\n",
    "house_links_pages = get_house_links(htmls, driver, next_page_xpath)\n",
    "driver.close()\n",
    "print('Finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 儲存房屋的html.csv\n",
    "save_html(house_links_pages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
